{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0bd793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots will be saved to: plots\n",
      "\n",
      "================================================================================\n",
      "LOADING DATA\n",
      "================================================================================\n",
      "✓ Loaded deterministic for size 50: 30 instances\n",
      "✓ Loaded random for size 50: 30 instances\n",
      "  Missing: results/50/local_search.csv\n",
      "  Missing: results/50/vnd.csv\n",
      "✓ Loaded beam_search for size 50: 30 instances\n",
      "✓ Loaded simulated_annealing for size 50: 30 instances\n",
      "✓ Loaded deterministic for size 100: 30 instances\n",
      "✓ Loaded random for size 100: 30 instances\n",
      "  Missing: results/100/local_search.csv\n",
      "  Missing: results/100/vnd.csv\n",
      "  Missing: results/100/beam_search.csv\n",
      "✓ Loaded simulated_annealing for size 100: 30 instances\n",
      "✓ Loaded deterministic for size 200: 30 instances\n",
      "✓ Loaded random for size 200: 30 instances\n",
      "  Missing: results/200/local_search.csv\n",
      "  Missing: results/200/vnd.csv\n",
      "  Missing: results/200/beam_search.csv\n",
      "  Missing: results/200/simulated_annealing.csv\n",
      "✓ Loaded deterministic for size 500: 30 instances\n",
      "✓ Loaded random for size 500: 30 instances\n",
      "  Missing: results/500/local_search.csv\n",
      "  Missing: results/500/vnd.csv\n",
      "  Missing: results/500/beam_search.csv\n",
      "  Missing: results/500/simulated_annealing.csv\n",
      "✓ Loaded deterministic for size 1000: 30 instances\n",
      "✓ Loaded random for size 1000: 30 instances\n",
      "  Missing: results/1000/local_search.csv\n",
      "  Missing: results/1000/vnd.csv\n",
      "  Missing: results/1000/beam_search.csv\n",
      "  Missing: results/1000/simulated_annealing.csv\n",
      "✓ Loaded deterministic for size 2000: 30 instances\n",
      "✓ Loaded random for size 2000: 30 instances\n",
      "  Missing: results/2000/local_search.csv\n",
      "  Missing: results/2000/vnd.csv\n",
      "  Missing: results/2000/beam_search.csv\n",
      "  Missing: results/2000/simulated_annealing.csv\n",
      "✓ Loaded deterministic for size 5000: 30 instances\n",
      "  Missing: results/5000/random.csv\n",
      "  Missing: results/5000/local_search.csv\n",
      "  Missing: results/5000/vnd.csv\n",
      "  Missing: results/5000/beam_search.csv\n",
      "  Missing: results/5000/simulated_annealing.csv\n",
      "✓ Loaded deterministic for size 10000: 30 instances\n",
      "  Missing: results/10000/random.csv\n",
      "  Missing: results/10000/local_search.csv\n",
      "  Missing: results/10000/vnd.csv\n",
      "  Missing: results/10000/beam_search.csv\n",
      "  Missing: results/10000/simulated_annealing.csv\n",
      "\n",
      "Total records loaded: 510\n",
      "Algorithms found: ['deterministic' 'random' 'beam_search' 'simulated_annealing']\n",
      "Instance sizes found: [np.int64(50), np.int64(100), np.int64(200), np.int64(500), np.int64(1000), np.int64(2000), np.int64(5000), np.int64(10000)]\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "                                   time_seconds_mean  time_seconds_std  \\\n",
      "algorithm           instance_size                                        \n",
      "beam_search         50                        3.0140            0.1618   \n",
      "deterministic       50                        0.0008            0.0001   \n",
      "                    100                       0.0030            0.0002   \n",
      "                    200                       0.0131            0.0014   \n",
      "                    500                       0.0728            0.0013   \n",
      "                    1000                      0.2949            0.0078   \n",
      "                    2000                      1.1978            0.0658   \n",
      "                    5000                      8.2160            0.3343   \n",
      "                    10000                    39.3703            5.9654   \n",
      "random              50                        0.0001            0.0000   \n",
      "                    100                       0.0002            0.0000   \n",
      "                    200                       0.0004            0.0000   \n",
      "                    500                       0.0019            0.0002   \n",
      "                    1000                      0.0064            0.0004   \n",
      "                    2000                      0.0271            0.0037   \n",
      "simulated_annealing 50                        0.0540            0.0033   \n",
      "                    100                       0.1390            0.0118   \n",
      "\n",
      "                                   time_seconds_min  time_seconds_max  \\\n",
      "algorithm           instance_size                                       \n",
      "beam_search         50                       2.7184            3.3444   \n",
      "deterministic       50                       0.0007            0.0010   \n",
      "                    100                      0.0027            0.0036   \n",
      "                    200                      0.0113            0.0185   \n",
      "                    500                      0.0716            0.0789   \n",
      "                    1000                     0.2845            0.3201   \n",
      "                    2000                     1.1318            1.3959   \n",
      "                    5000                     7.7381            8.8927   \n",
      "                    10000                   35.8770           69.4405   \n",
      "random              50                       0.0001            0.0001   \n",
      "                    100                      0.0001            0.0003   \n",
      "                    200                      0.0003            0.0005   \n",
      "                    500                      0.0016            0.0029   \n",
      "                    1000                     0.0058            0.0076   \n",
      "                    2000                     0.0235            0.0364   \n",
      "simulated_annealing 50                       0.0486            0.0614   \n",
      "                    100                      0.1233            0.1741   \n",
      "\n",
      "                                   objective_value_mean  objective_value_std  \\\n",
      "algorithm           instance_size                                              \n",
      "beam_search         50                     2.129338e+03             282.3170   \n",
      "deterministic       50                     3.348063e+03             188.0173   \n",
      "                    100                    9.290229e+03             415.4150   \n",
      "                    200                    2.679934e+04            1315.4591   \n",
      "                    500                    1.052908e+05            3630.3325   \n",
      "                    1000                   2.927319e+05           10119.9871   \n",
      "                    2000                   8.358370e+05           33518.4336   \n",
      "                    5000                   3.288190e+06           76361.8578   \n",
      "                    10000                  6.407548e+05           13174.5643   \n",
      "random              50                     3.377093e+03             231.7155   \n",
      "                    100                    9.396724e+03             398.8110   \n",
      "                    200                    2.700534e+04            1518.1375   \n",
      "                    500                    1.069076e+05            3410.3321   \n",
      "                    1000                   2.979882e+05            9413.4705   \n",
      "                    2000                   8.512883e+05           35598.9067   \n",
      "simulated_annealing 50                     3.405682e+03             211.7108   \n",
      "                    100                    9.401524e+03             529.5190   \n",
      "\n",
      "                                   objective_value_min  objective_value_max  \\\n",
      "algorithm           instance_size                                             \n",
      "beam_search         50                    1.688790e+03         2.815040e+03   \n",
      "deterministic       50                    3.065111e+03         3.773147e+03   \n",
      "                    100                   8.265172e+03         1.020600e+04   \n",
      "                    200                   2.411065e+04         2.969459e+04   \n",
      "                    500                   9.810701e+04         1.121090e+05   \n",
      "                    1000                  2.748098e+05         3.103893e+05   \n",
      "                    2000                  7.903879e+05         8.996533e+05   \n",
      "                    5000                  3.135004e+06         3.453781e+06   \n",
      "                    10000                 6.183454e+05         6.657750e+05   \n",
      "random              50                    3.029603e+03         3.969000e+03   \n",
      "                    100                   8.019232e+03         1.013502e+04   \n",
      "                    200                   2.407731e+04         3.075139e+04   \n",
      "                    500                   9.957345e+04         1.129657e+05   \n",
      "                    1000                  2.839137e+05         3.129967e+05   \n",
      "                    2000                  7.976332e+05         9.167194e+05   \n",
      "simulated_annealing 50                    2.912440e+03         3.855970e+03   \n",
      "                    100                   8.009225e+03         1.042377e+04   \n",
      "\n",
      "                                   jain_fairness_mean  jain_fairness_std  \\\n",
      "algorithm           instance_size                                          \n",
      "beam_search         50                         0.5000             0.0000   \n",
      "deterministic       50                         0.9952             0.0078   \n",
      "                    100                        0.9972             0.0037   \n",
      "                    200                        0.9967             0.0026   \n",
      "                    500                        0.9959             0.0032   \n",
      "                    1000                       0.9960             0.0013   \n",
      "                    2000                       0.9963             0.0007   \n",
      "                    5000                       0.9963             0.0005   \n",
      "                    10000                      0.9587             0.0034   \n",
      "random              50                         0.9813             0.0206   \n",
      "                    100                        0.9891             0.0153   \n",
      "                    200                        0.9861             0.0127   \n",
      "                    500                        0.9777             0.0104   \n",
      "                    1000                       0.9779             0.0063   \n",
      "                    2000                       0.9756             0.0053   \n",
      "simulated_annealing 50                         0.5000             0.0000   \n",
      "                    100                        0.5000             0.0000   \n",
      "\n",
      "                                   jain_fairness_min  jain_fairness_max  \\\n",
      "algorithm           instance_size                                         \n",
      "beam_search         50                        0.5000             0.5000   \n",
      "deterministic       50                        0.9626             1.0000   \n",
      "                    100                       0.9850             1.0000   \n",
      "                    200                       0.9890             0.9996   \n",
      "                    500                       0.9822             0.9996   \n",
      "                    1000                      0.9929             0.9980   \n",
      "                    2000                      0.9942             0.9975   \n",
      "                    5000                      0.9952             0.9974   \n",
      "                    10000                     0.9519             0.9654   \n",
      "random              50                        0.9079             1.0000   \n",
      "                    100                       0.9408             1.0000   \n",
      "                    200                       0.9335             0.9998   \n",
      "                    500                       0.9500             0.9910   \n",
      "                    1000                      0.9678             0.9916   \n",
      "                    2000                      0.9603             0.9859   \n",
      "simulated_annealing 50                        0.5000             0.5000   \n",
      "                    100                       0.5000             0.5000   \n",
      "\n",
      "                                   num_instances  \n",
      "algorithm           instance_size                 \n",
      "beam_search         50                        30  \n",
      "deterministic       50                        30  \n",
      "                    100                       30  \n",
      "                    200                       30  \n",
      "                    500                       30  \n",
      "                    1000                      30  \n",
      "                    2000                      30  \n",
      "                    5000                      30  \n",
      "                    10000                     30  \n",
      "random              50                        30  \n",
      "                    100                       30  \n",
      "                    200                       30  \n",
      "                    500                       30  \n",
      "                    1000                      30  \n",
      "                    2000                      30  \n",
      "simulated_annealing 50                        30  \n",
      "                    100                       30  \n",
      "\n",
      "Summary statistics saved to plots/summary_statistics.csv\n",
      "\n",
      "================================================================================\n",
      "GENERATING PLOTS\n",
      "================================================================================\n",
      "1. Runtime Analysis...\n",
      "   ✓ Saved: plots/runtime_analysis.png\n",
      "2. Objective Value Analysis...\n",
      "   ✓ Saved: plots/objective_value_analysis.png\n",
      "3. Jain Fairness Analysis...\n",
      "   ✓ Saved: plots/jain_fairness_analysis.png\n",
      "4. Performance Trade-offs...\n",
      "   ✓ Saved: plots/performance_tradeoffs.png\n",
      "5. Scalability Analysis...\n",
      "   ✓ Saved: plots/scalability_analysis.png\n",
      "\n",
      "================================================================================\n",
      "STATISTICAL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "1. Average Runtime Ranking (lower is better):\n",
      "   1. random              : 0.006004 seconds\n",
      "   2. simulated_annealing : 0.096506 seconds\n",
      "   3. beam_search         : 3.014048 seconds\n",
      "   4. deterministic       : 6.146084 seconds\n",
      "\n",
      "2. Average Objective Value Ranking (higher is better):\n",
      "   1. deterministic       : 650280.32\n",
      "   2. random              : 215993.87\n",
      "   3. simulated_annealing : 6403.60\n",
      "   4. beam_search         : 2129.34\n",
      "\n",
      "3. Average Jain Fairness Ranking (higher is better):\n",
      "   1. deterministic       : 0.991524\n",
      "   2. random              : 0.981293\n",
      "   3. beam_search         : 0.500000\n",
      "   4. simulated_annealing : 0.500000\n",
      "\n",
      "4. Instance Count by Size:\n",
      "   Size     50:  120 instances\n",
      "   Size    100:   90 instances\n",
      "   Size    200:   60 instances\n",
      "   Size    500:   60 instances\n",
      "   Size   1000:   60 instances\n",
      "   Size   2000:   60 instances\n",
      "   Size   5000:   30 instances\n",
      "   Size  10000:   30 instances\n",
      "\n",
      "================================================================================\n",
      "EXPORTING RESULTS\n",
      "================================================================================\n",
      "✓ Complete results exported to: plots/complete_results.csv\n",
      "✓ Algorithm comparison exported to: plots/algorithm_comparison_by_size.csv\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "All plots and results saved to: plots/\n",
      "  - runtime_analysis.png\n",
      "  - objective_value_analysis.png\n",
      "  - jain_fairness_analysis.png\n",
      "  - performance_tradeoffs.png\n",
      "  - scalability_analysis.png\n",
      "  - summary_statistics.csv\n",
      "  - complete_results.csv\n",
      "  - algorithm_comparison_by_size.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Algorithm Performance Analysis Script\n",
    "Analyzes runtimes and objective values across different algorithms and instance sizes\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuration\n",
    "result_dir = \"results\"\n",
    "req_sizes = [\"50\", \"100\", \"200\", \"500\"]\n",
    "algs = [\"deterministic\", \"random\", \"local_search\", \"vnd\", \"beam_search\", \"simulated_annealing\"]\n",
    "\n",
    "# Create plots directory\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "print(f\"Plots will be saved to: {plots_dir}\")\n",
    "\n",
    "# Load all data\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*80)\n",
    "all_data = []\n",
    "\n",
    "for req_size in req_sizes:\n",
    "    for alg in algs:\n",
    "        file_path = os.path.join(result_dir, req_size, f\"{alg}.csv\")\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                df['algorithm'] = alg\n",
    "                df['instance_size'] = int(req_size)\n",
    "                all_data.append(df)\n",
    "                print(f\"✓ Loaded {alg} for size {req_size}: {len(df)} instances\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error loading {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"  Missing: {file_path}\")\n",
    "\n",
    "# Combine all data\n",
    "if all_data:\n",
    "    df_all = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nTotal records loaded: {len(df_all)}\")\n",
    "    print(f\"Algorithms found: {df_all['algorithm'].unique()}\")\n",
    "    print(f\"Instance sizes found: {sorted(df_all['instance_size'].unique())}\")\n",
    "else:\n",
    "    print(\"No data loaded! Please check your file paths.\")\n",
    "    exit(1)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "summary_stats = df_all.groupby(['algorithm', 'instance_size']).agg({\n",
    "    'time_seconds': ['mean', 'std', 'min', 'max'],\n",
    "    'objective_value': ['mean', 'std', 'min', 'max'],\n",
    "    'jain_fairness': ['mean', 'std', 'min', 'max'],\n",
    "    'instance_name': 'count'\n",
    "}).round(4)\n",
    "\n",
    "summary_stats.columns = ['_'.join(col).strip() for col in summary_stats.columns.values]\n",
    "summary_stats = summary_stats.rename(columns={'instance_name_count': 'num_instances'})\n",
    "print(summary_stats)\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_stats.to_csv(os.path.join(plots_dir, 'summary_statistics.csv'))\n",
    "print(f\"\\nSummary statistics saved to {plots_dir}/summary_statistics.csv\")\n",
    "\n",
    "# Plot 1: Runtime Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING PLOTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Runtime Analysis...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1.1: Box plot of runtimes by algorithm\n",
    "ax = axes[0, 0]\n",
    "df_all.boxplot(column='time_seconds', by='algorithm', ax=ax)\n",
    "ax.set_title('Runtime Distribution by Algorithm', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Algorithm', fontsize=12)\n",
    "ax.set_ylabel('Time (seconds)', fontsize=12)\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Plot 1.2: Average runtime by instance size and algorithm\n",
    "ax = axes[0, 1]\n",
    "avg_runtime = df_all.groupby(['instance_size', 'algorithm'])['time_seconds'].mean().unstack()\n",
    "avg_runtime.plot(ax=ax, marker='o', linewidth=2)\n",
    "ax.set_title('Average Runtime vs Instance Size', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Average Time (seconds)', fontsize=12)\n",
    "ax.legend(title='Algorithm', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Plot 1.3: Runtime heatmap\n",
    "ax = axes[1, 0]\n",
    "pivot_runtime = df_all.pivot_table(values='time_seconds', \n",
    "                                   index='algorithm', \n",
    "                                   columns='instance_size', \n",
    "                                   aggfunc='mean')\n",
    "sns.heatmap(pivot_runtime, annot=True, fmt='.4f', cmap='YlOrRd', ax=ax, cbar_kws={'label': 'Time (seconds)'})\n",
    "ax.set_title('Average Runtime Heatmap', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Algorithm', fontsize=12)\n",
    "\n",
    "# Plot 1.4: Violin plot for selected instance sizes\n",
    "ax = axes[1, 1]\n",
    "selected_sizes = [int(s) for s in req_sizes if int(s) in df_all['instance_size'].values][:4]\n",
    "df_selected = df_all[df_all['instance_size'].isin(selected_sizes)]\n",
    "if not df_selected.empty:\n",
    "    sns.violinplot(data=df_selected, x='algorithm', y='time_seconds', ax=ax)\n",
    "    ax.set_title(f'Runtime Distribution (Selected Sizes: {selected_sizes})', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Algorithm', fontsize=12)\n",
    "    ax.set_ylabel('Time (seconds)', fontsize=12)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'runtime_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"   ✓ Saved: {plots_dir}/runtime_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Objective Value Analysis\n",
    "print(\"2. Objective Value Analysis...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 2.1: Box plot of objective values by algorithm\n",
    "ax = axes[0, 0]\n",
    "df_all.boxplot(column='objective_value', by='algorithm', ax=ax)\n",
    "ax.set_title('Objective Value Distribution by Algorithm', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Algorithm', fontsize=12)\n",
    "ax.set_ylabel('Objective Value', fontsize=12)\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Plot 2.2: Average objective value by instance size and algorithm\n",
    "ax = axes[0, 1]\n",
    "avg_objective = df_all.groupby(['instance_size', 'algorithm'])['objective_value'].mean().unstack()\n",
    "avg_objective.plot(ax=ax, marker='o', linewidth=2)\n",
    "ax.set_title('Average Objective Value vs Instance Size', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Average Objective Value', fontsize=12)\n",
    "ax.legend(title='Algorithm', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2.3: Objective value heatmap\n",
    "ax = axes[1, 0]\n",
    "pivot_objective = df_all.pivot_table(values='objective_value', \n",
    "                                     index='algorithm', \n",
    "                                     columns='instance_size', \n",
    "                                     aggfunc='mean')\n",
    "sns.heatmap(pivot_objective, annot=True, fmt='.1f', cmap='RdYlGn', ax=ax, \n",
    "            cbar_kws={'label': 'Objective Value'})\n",
    "ax.set_title('Average Objective Value Heatmap', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Algorithm', fontsize=12)\n",
    "\n",
    "# Plot 2.4: Standard deviation of objective values\n",
    "ax = axes[1, 1]\n",
    "std_objective = df_all.groupby(['instance_size', 'algorithm'])['objective_value'].std().unstack()\n",
    "std_objective.plot(ax=ax, marker='s', linewidth=2, linestyle='--')\n",
    "ax.set_title('Objective Value Standard Deviation vs Instance Size', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Standard Deviation', fontsize=12)\n",
    "ax.legend(title='Algorithm', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'objective_value_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"   ✓ Saved: {plots_dir}/objective_value_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 3: Jain Fairness Analysis\n",
    "print(\"3. Jain Fairness Analysis...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 3.1: Box plot of Jain fairness by algorithm\n",
    "ax = axes[0, 0]\n",
    "df_all.boxplot(column='jain_fairness', by='algorithm', ax=ax)\n",
    "ax.set_title('Jain Fairness Distribution by Algorithm', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Algorithm', fontsize=12)\n",
    "ax.set_ylabel('Jain Fairness Index', fontsize=12)\n",
    "ax.set_ylim([0.95, 1.005])\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Plot 3.2: Average Jain fairness by instance size and algorithm\n",
    "ax = axes[0, 1]\n",
    "avg_fairness = df_all.groupby(['instance_size', 'algorithm'])['jain_fairness'].mean().unstack()\n",
    "avg_fairness.plot(ax=ax, marker='o', linewidth=2)\n",
    "ax.set_title('Average Jain Fairness vs Instance Size', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Average Jain Fairness', fontsize=12)\n",
    "ax.legend(title='Algorithm', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0.95, 1.005])\n",
    "\n",
    "# Plot 3.3: Fairness heatmap\n",
    "ax = axes[1, 0]\n",
    "pivot_fairness = df_all.pivot_table(values='jain_fairness', \n",
    "                                    index='algorithm', \n",
    "                                    columns='instance_size', \n",
    "                                    aggfunc='mean')\n",
    "sns.heatmap(pivot_fairness, annot=True, fmt='.4f', cmap='YlGn', ax=ax, \n",
    "            cbar_kws={'label': 'Jain Fairness'}, vmin=0.95, vmax=1.0)\n",
    "ax.set_title('Average Jain Fairness Heatmap', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Algorithm', fontsize=12)\n",
    "\n",
    "# Plot 3.4: Histogram of fairness values\n",
    "ax = axes[1, 1]\n",
    "for alg in df_all['algorithm'].unique():\n",
    "    data = df_all[df_all['algorithm'] == alg]['jain_fairness']\n",
    "    ax.hist(data, alpha=0.5, bins=30, label=alg, edgecolor='black')\n",
    "ax.set_title('Jain Fairness Distribution Histogram', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Jain Fairness Index', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.legend(title='Algorithm')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'jain_fairness_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"   ✓ Saved: {plots_dir}/jain_fairness_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 4: Performance Trade-offs\n",
    "print(\"4. Performance Trade-offs...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 4.1: Runtime vs Objective Value scatter\n",
    "ax = axes[0, 0]\n",
    "for alg in df_all['algorithm'].unique():\n",
    "    data = df_all[df_all['algorithm'] == alg]\n",
    "    ax.scatter(data['time_seconds'], data['objective_value'], \n",
    "              alpha=0.6, s=50, label=alg, edgecolors='black', linewidth=0.5)\n",
    "ax.set_title('Runtime vs Objective Value', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Time (seconds)', fontsize=12)\n",
    "ax.set_ylabel('Objective Value', fontsize=12)\n",
    "ax.legend(title='Algorithm')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "# Plot 4.2: Runtime vs Jain Fairness scatter\n",
    "ax = axes[0, 1]\n",
    "for alg in df_all['algorithm'].unique():\n",
    "    data = df_all[df_all['algorithm'] == alg]\n",
    "    ax.scatter(data['time_seconds'], data['jain_fairness'], \n",
    "              alpha=0.6, s=50, label=alg, edgecolors='black', linewidth=0.5)\n",
    "ax.set_title('Runtime vs Jain Fairness', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Time (seconds)', fontsize=12)\n",
    "ax.set_ylabel('Jain Fairness Index', fontsize=12)\n",
    "ax.legend(title='Algorithm')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim([0.95, 1.005])\n",
    "\n",
    "# Plot 4.3: Objective Value vs Jain Fairness scatter\n",
    "ax = axes[1, 0]\n",
    "for alg in df_all['algorithm'].unique():\n",
    "    data = df_all[df_all['algorithm'] == alg]\n",
    "    ax.scatter(data['objective_value'], data['jain_fairness'], \n",
    "              alpha=0.6, s=50, label=alg, edgecolors='black', linewidth=0.5)\n",
    "ax.set_title('Objective Value vs Jain Fairness', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Objective Value', fontsize=12)\n",
    "ax.set_ylabel('Jain Fairness Index', fontsize=12)\n",
    "ax.legend(title='Algorithm')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0.95, 1.005])\n",
    "\n",
    "# Plot 4.4: Normalized performance comparison\n",
    "ax = axes[1, 1]\n",
    "available_sizes = sorted(df_all['instance_size'].unique())\n",
    "if available_sizes:\n",
    "    selected_size = available_sizes[0]\n",
    "    df_radar = df_all[df_all['instance_size'] == selected_size].groupby('algorithm').agg({\n",
    "        'time_seconds': 'mean',\n",
    "        'objective_value': 'mean',\n",
    "        'jain_fairness': 'mean'\n",
    "    })\n",
    "    \n",
    "    # Normalize metrics (higher is better)\n",
    "    df_radar['time_norm'] = 1 - (df_radar['time_seconds'] - df_radar['time_seconds'].min()) / (df_radar['time_seconds'].max() - df_radar['time_seconds'].min() + 1e-10)\n",
    "    df_radar['obj_norm'] = (df_radar['objective_value'] - df_radar['objective_value'].min()) / (df_radar['objective_value'].max() - df_radar['objective_value'].min() + 1e-10)\n",
    "    df_radar['fair_norm'] = df_radar['jain_fairness']\n",
    "    \n",
    "    metrics = ['Speed\\\\n(norm)', 'Objective\\\\n(norm)', 'Fairness\\\\n(norm)']\n",
    "    x_pos = np.arange(len(metrics))\n",
    "    width = 0.15\n",
    "    \n",
    "    for i, alg in enumerate(df_radar.index):\n",
    "        values = [df_radar.loc[alg, 'time_norm'], \n",
    "                 df_radar.loc[alg, 'obj_norm'], \n",
    "                 df_radar.loc[alg, 'fair_norm']]\n",
    "        ax.bar(x_pos + i*width, values, width, label=alg, alpha=0.8)\n",
    "    \n",
    "    ax.set_title(f'Normalized Performance Comparison (Size {selected_size})', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Normalized Score (0-1)', fontsize=12)\n",
    "    ax.set_xticks(x_pos + width * (len(df_radar) - 1) / 2)\n",
    "    ax.set_xticklabels(metrics, fontsize=10)\n",
    "    ax.legend(title='Algorithm', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'performance_tradeoffs.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"   ✓ Saved: {plots_dir}/performance_tradeoffs.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot 5: Scalability Analysis\n",
    "print(\"5. Scalability Analysis...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 5.1: Log-log plot of runtime scaling\n",
    "ax = axes[0]\n",
    "avg_runtime_by_size = df_all.groupby(['instance_size', 'algorithm'])['time_seconds'].mean().unstack()\n",
    "for alg in avg_runtime_by_size.columns:\n",
    "    data = avg_runtime_by_size[alg].dropna()\n",
    "    ax.plot(data.index, data.values, marker='o', linewidth=2, label=alg, markersize=8)\n",
    "ax.set_title('Runtime Scaling (Log-Log)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Average Time in seconds (log scale)', fontsize=12)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend(title='Algorithm')\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "# Plot 5.2: Relative performance compared to fastest algorithm\n",
    "ax = axes[1]\n",
    "min_times = df_all.groupby('instance_size')['time_seconds'].min()\n",
    "relative_performance = {}\n",
    "\n",
    "for alg in df_all['algorithm'].unique():\n",
    "    alg_times = df_all[df_all['algorithm'] == alg].groupby('instance_size')['time_seconds'].mean()\n",
    "    relative_performance[alg] = (alg_times / min_times).dropna()\n",
    "\n",
    "for alg, rel_perf in relative_performance.items():\n",
    "    ax.plot(rel_perf.index, rel_perf.values, marker='s', linewidth=2, label=alg, markersize=8)\n",
    "\n",
    "ax.set_title('Relative Performance vs Best Algorithm', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Instance Size', fontsize=12)\n",
    "ax.set_ylabel('Slowdown Factor (vs fastest)', fontsize=12)\n",
    "ax.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Fastest')\n",
    "ax.legend(title='Algorithm')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'scalability_analysis.png'), dpi=300, bbox_inches='tight')\n",
    "print(f\"   ✓ Saved: {plots_dir}/scalability_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# Statistical Comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Average Runtime Ranking (lower is better):\")\n",
    "runtime_ranking = df_all.groupby('algorithm')['time_seconds'].mean().sort_values()\n",
    "for i, (alg, time) in enumerate(runtime_ranking.items(), 1):\n",
    "    print(f\"   {i}. {alg:20s}: {time:.6f} seconds\")\n",
    "\n",
    "print(\"\\n2. Average Objective Value Ranking (higher is better):\")\n",
    "objective_ranking = df_all.groupby('algorithm')['objective_value'].mean().sort_values(ascending=False)\n",
    "for i, (alg, obj) in enumerate(objective_ranking.items(), 1):\n",
    "    print(f\"   {i}. {alg:20s}: {obj:.2f}\")\n",
    "\n",
    "print(\"\\n3. Average Jain Fairness Ranking (higher is better):\")\n",
    "fairness_ranking = df_all.groupby('algorithm')['jain_fairness'].mean().sort_values(ascending=False)\n",
    "for i, (alg, fair) in enumerate(fairness_ranking.items(), 1):\n",
    "    print(f\"   {i}. {alg:20s}: {fair:.6f}\")\n",
    "\n",
    "print(\"\\n4. Instance Count by Size:\")\n",
    "size_counts = df_all.groupby('instance_size')['instance_name'].count().sort_index()\n",
    "for size, count in size_counts.items():\n",
    "    print(f\"   Size {size:6d}: {count:4d} instances\")\n",
    "\n",
    "# Export results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_file = os.path.join(plots_dir, 'complete_results.csv')\n",
    "df_all.to_csv(output_file, index=False)\n",
    "print(f\"✓ Complete results exported to: {output_file}\")\n",
    "\n",
    "comparison_file = os.path.join(plots_dir, 'algorithm_comparison_by_size.csv')\n",
    "comparison = df_all.groupby(['instance_size', 'algorithm']).agg({\n",
    "    'time_seconds': ['mean', 'std'],\n",
    "    'objective_value': ['mean', 'std'],\n",
    "    'jain_fairness': ['mean', 'std'],\n",
    "    'instance_name': 'count'\n",
    "}).round(6)\n",
    "comparison.to_csv(comparison_file)\n",
    "print(f\"✓ Algorithm comparison exported to: {comparison_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAll plots and results saved to: {plots_dir}/\")\n",
    "print(\"  - runtime_analysis.png\")\n",
    "print(\"  - objective_value_analysis.png\")\n",
    "print(\"  - jain_fairness_analysis.png\")\n",
    "print(\"  - performance_tradeoffs.png\")\n",
    "print(\"  - scalability_analysis.png\")\n",
    "print(\"  - summary_statistics.csv\")\n",
    "print(\"  - complete_results.csv\")\n",
    "print(\"  - algorithm_comparison_by_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd03065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f540c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
